{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top10 Topic Instagram Crawling\n",
    "\n",
    "# 게시물, 댓글, 해시태그를 크롤링해봅니다\n",
    "#   \n",
    "\n",
    "- 원하든 키워드에 대한 게시물의 URL을 검색하고\n",
    "- URL을 통해 게시물의 내용, 댓글, 해시태그를 크롤링 합니다\n",
    "#    \n",
    "\n",
    "![jpeg](https://i1.wp.com/kokolevel.com/wp-content/uploads/2018/10/Instagram.png?w=1620&ssl=1)\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드에 대한 url을 검색하고 url list에 저장\n",
    "# 그 url list에 대해 게시물과 댓글을 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['society', 'politics', 'economic', 'foreign', 'culture',\n",
    "          'entertain', 'sports', 'digital']\n",
    "\n",
    "total_keyword_ranking10 = [['서울', '출근길', '개혁', '화재', '국정원검찰경찰', '대통령', '한화', '개최', '성추행', '이호진'], ['개혁', '대통령', '518', '한국당', '후보', '망언', '국정원검찰경찰', '이낙연', '이해찬', '전략회의'], ['대비', '전일', '영업익', '홍남기', '작년', '지난해', '상승', '결정', '코스피', '하락한'], ['2019', '트럼프', '미중', '무역협상', '폼페이오', '국가비상사태', '비핵화', '()', '류현진', '--'], ['출근길', '내리는', '내린', '출시', '서울', '김수환', '중부', '곳곳', '추기경', '전국'], ['열혈사제', '이하늬', '공개', '김남길', '이대휘', '졸업', '고아성', '품격', '미소', '황후의'], ['감독', '손흥민', '남북', '치어리더', '단일팀', '2019시즌', '류현진', '가스파리니', '공동', '대한항공'], ['진교영', '네이버', 'KT', '출시', '넥슨', 'AI', '모바일', '개최', '트라하', 'LG유플러스']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해시태그를 검색한 페이지에서 ID(검색에 필요한 url)을 검색하는 함수\n",
    "\n",
    "def crawl_ID(soup):\n",
    "    \n",
    "    ID_list = []\n",
    "    \n",
    "    while len(soup) > 16000:\n",
    "        ID_first_index = soup.find('shortcode')\n",
    "        ID_last_index = soup.find('edge_media_to_comment')\n",
    "        ID = soup[ID_first_index+12 : ID_last_index-3]\n",
    "    \n",
    "        # url이 아닌것은 pass\n",
    "        if(len(ID)>20):\n",
    "            break\n",
    "    \n",
    "        # 다음 url을 찾기 위해 슬라이싱\n",
    "        soup = soup[ID_last_index+100:]\n",
    "        # list에 추가\n",
    "        ID_list.append(ID)\n",
    "\n",
    "    # ID list 중복처리\n",
    "    ID_list = set(ID_list)\n",
    "    return ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "topic_index = 0\n",
    "\n",
    "topic_list = []\n",
    "main_content_list = []\n",
    "comments_list = []\n",
    "\n",
    "\n",
    "for topic in topics[0:1]:\n",
    "    \n",
    "    print('Topic : {}\\n'.format(topic))\n",
    "    \n",
    "    for keyword in total_keyword_ranking10[topic_index]:\n",
    "        \n",
    "        print('{}에 대한 게시물을 검색합니다'.format(keyword))\n",
    "        \n",
    "        url = 'https://www.instagram.com/explore/tags/{}'.format(keyword)\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        soup = str(soup)\n",
    "\n",
    "        ID_list = crawl_ID(soup)\n",
    "        \n",
    "        for id in ID_list:\n",
    "            \n",
    "            url = 'https://www.instagram.com/p/{}'.format(id)\n",
    "            driver = webdriver.Chrome('/home/apostcto/ITDA/chromedriver')\n",
    "            driver.get(url)\n",
    "\n",
    "            contents_elements = driver.find_element_by_css_selector('.eo2As .gElp9').text\n",
    "            comments_elements = driver.find_elements(By.CSS_SELECTOR, '.eo2As .gElp9')[1:]\n",
    "\n",
    "            \n",
    "            \n",
    "            for comment_element in comments_elements:\n",
    "   \n",
    "                text = comment_element.text\n",
    "                comment_index = text.find('\\n')\n",
    "    \n",
    "                comment = text[comment_index+1:]\n",
    "                comments_list.append(comment)\n",
    "                \n",
    "                # DataFrame을 생성하기 위해 추가해줍니다\n",
    "                topic_list.append(topic)\n",
    "                main_content_list.append(keyword)\n",
    "                comments_list.append(comment)\n",
    "        \n",
    "            # 차단을 막기위해 sleep\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "    topic_index += 1\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
